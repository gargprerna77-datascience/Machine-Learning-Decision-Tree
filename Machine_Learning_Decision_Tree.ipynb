{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of classification?\n",
        "\n",
        "Answer:\n",
        "A Decision Tree is a supervised machine learning algorithm that uses a flowchart-like structure to predict categorical outcomes. It works by recursively partitioning data into smaller subsets based on attribute tests at internal nodes, creating branches for attribute values, and ending with leaf nodes that represent final class labels. During classification, the tree sorts new data points from the root node down to a leaf node based on a series of conditions, ultimately assigning them to a specific category.\n",
        "\n",
        "How it Works for Classification\n",
        "\n",
        "Root Node: The process begins at the root node, which represents the entire dataset and the initial feature for splitting.\n",
        "\n",
        "Internal Nodes (Decision Nodes): These nodes represent tests on specific attributes (features) of the data.\n",
        "\n",
        "Branches: Branches extend from the internal nodes, representing the possible outcomes or values of the attribute being tested.\n",
        "\n",
        "Leaf Nodes (Terminal Nodes): These nodes represent the final decision or prediction, which is a specific class label. A new data point is classified by following the path from the root to a leaf node based on its features.\n",
        "\n",
        "Splitting Criteria: The tree uses algorithms to determine the best attribute to split the data at each node, aiming to create \"pure\" nodes where all data points belong to the same class. Common splitting measures include Gini impurity and information gain.\n",
        "\n",
        "Example of Classification\n",
        "\n",
        "Imagine classifying emails as \"spam\" or \"not spam\".\n",
        "The root node might test for the presence of certain keywords in the email.\n",
        "\n",
        "If the email contains \"free money,\" a branch leads to a decision node.\n",
        "This node might then test for the sender's address.\n",
        "Eventually, the path leads to a leaf node indicating the email is \"spam\".\n",
        "\n",
        "In essence, a decision tree makes a series of \"if-then-else\" decisions based on the features of a new data point to arrive at a final classification."
      ],
      "metadata": {
        "id": "XnLwwb6-l6_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "\n",
        "Answer:  Gini Impurity and Entropy are splitting criteria used in decision trees to measure the impurity or disorder of a node, with lower values indicating higher purity and a better split. Gini Impurity calculates the probability of misclassification, while Entropy quantifies the \"uncertainty\" or disorder of the node's classes. Decision trees use these measures to select the feature and split point that result in the largest reduction in impurity (or the highest information gain), thus leading to more accurate and pure leaf nodes.\n",
        "Gini Impurity\n",
        "\n",
        "Concept: Gini Impurity is a measure that quantifies the likelihood of a randomly chosen example from a node being incorrectly classified if it were randomly labeled according to the class distribution in that node.\n",
        "Scale: It ranges from 0 to 1.\n",
        "\n",
        "Interpretation:\n",
        "A Gini Impurity of 0 means the node is perfectly pure, with all data points belonging to a single class.\n",
        "A Gini Impurity of 1 indicates maximum impurity, where data points are evenly distributed across all classes (e.g., a 50-50 split).\n",
        "Entropy\n",
        "\n",
        "Concept: Entropy is a measure of the disorder or randomness within a set of data points at a node. It quantifies the amount of \"surprise\" or \"uncertainty\" associated with the outcomes of a random variable.\n",
        "Scale: It also ranges from 0 to 1.\n",
        "\n",
        "Interpretation:\n",
        "An entropy of 0 indicates a pure node, where all data points belong to the same class.\n",
        "A higher entropy value means the data points are more mixed and less pure, indicating greater disorder.\n",
        "\n",
        "Impact on Splits in a Decision Tree\n",
        "\n",
        "Objective: The goal of a decision tree is to create splits that result in pure leaf nodes, where all data points belong to a single class.\n",
        "\n",
        "Evaluation: At each node, the algorithm calculates the Gini Impurity or Entropy for potential splits based on different features.\n",
        "\n",
        "Best Split Selection: The algorithm then selects the feature and split point that yield the largest reduction in impurity. This is often framed as maximizing information gain, which is the difference between the parent node's impurity and the weighted average impurity of the child nodes.\n",
        "\n",
        "Outcome: This process continues recursively, creating a tree that progressively separates the data into increasingly pure subsets, ultimately leading to more accurate classification at the leaf nodes."
      ],
      "metadata": {
        "id": "xzzsr82_nDHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "\n",
        "Answer:  \n",
        "Pre-pruning stops a decision tree's growth early during training based on certain criteria to prevent overfitting, while post-pruning builds the full tree and then removes branches that are not essential to the model's accuracy after its creation. A practical advantage of pre-pruning is its efficiency, as it reduces computational cost by not growing the entire tree. A practical advantage of post-pruning is that it can lead to a more accurate model because it considers the full tree and is less likely to prematurely cut off branches that might be important for later splits.\n",
        "\n",
        "Pre-Pruning (Early Stopping)\n",
        "\n",
        "What it is: A technique that stops the tree-building process before the tree becomes too complex or deep.\n",
        "\n",
        "How it works: Restricts tree growth by setting stopping criteria, such as a maximum depth, minimum number of samples per leaf node, or a lack of significant improvement in splitting the data.\n",
        "\n",
        "Practical Advantage: Computational Efficiency: By preventing the tree from growing to its full potential, pre-pruning significantly reduces the training time and computational resources required to build the model.\n",
        "\n",
        "Post-Pruning (Reduced Error Pruning)\n",
        "\n",
        "What it is: A method that involves fully growing a decision tree and then subsequently trimming its branches and nodes.\n",
        "\n",
        "How it works: After the tree is fully grown, branches are removed if their removal does not decrease the accuracy of the model on a validation dataset.\n",
        "\n",
        "Practical Advantage: Improved Accuracy: Post-pruning often results in a more accurate model than pre-pruning because it avoids making greedy decisions early on that might later prove to be important. It allows the tree to first achieve a high level of classification for the training set, then refines it for better generalization."
      ],
      "metadata": {
        "id": "tIC9oX6nnuv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "\n",
        "Answer:\n",
        "Information Gain (IG) in decision trees quantifies how much a feature reduces uncertainty (entropy) about the target variable, thus making the resulting child nodes more homogeneous. It is crucial for choosing the best split because the feature with the highest information gain at any node is selected to split the data, leading to more effective classification by creating purer, more predictable child nodes.\n",
        "\n",
        "What is Information Gain?\n",
        "\n",
        "Reduction in Uncertainty: Information Gain measures the decrease in entropy (a measure of impurity or randomness) of the target variable after a split on a specific feature.\n",
        "\n",
        "Focus on Purity: When a decision tree splits data, it aims to create child nodes that are as \"pure\" as possible, meaning most samples in a node belong to the same class.\n",
        "\n",
        "How it's Calculated: It's calculated as the entropy of the parent node minus the weighted average entropy of the child nodes that result from the split.\n",
        "\n",
        "Formula: Gain(S, A) = Entropy(S) - Î£(|Sv| / |S|) * Entropy(Sv)\n",
        "S = parent node (the dataset)\n",
        "A = the feature being evaluated\n",
        "Sv = the subsets created by the split on attribute A\n",
        "\n",
        "Why is it Important for Choosing the Best Split?\n",
        "\n",
        "Maximizes Predictive Power: The primary goal of a decision tree is to effectively classify data. By maximizing Information Gain, the algorithm ensures it selects the feature that most significantly separates the classes.\n",
        "\n",
        "Creates More Homogeneous Nodes: A higher Information Gain means that the split on a feature results in child nodes with a more dominant class. This reduces the need for further branching and leads to a simpler, more accurate tree.\n",
        "\n",
        "Guides the Tree Building Process: At each step of building the decision tree, Information Gain is calculated for all available features. The feature that yields the highest Information Gain is chosen as the best feature to split the current node. This greedy approach ensures the tree is constructed in a way that progressively reduces uncertainty about the target variable."
      ],
      "metadata": {
        "id": "2kXAIWv2oLe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n",
        "\n",
        "Answer:\n",
        "Decision trees are used in many fields, such as medicine for diagnosis, finance for fraud detection and loan approval, and marketing for customer churn prediction. Their main advantages include being easy to understand and interpret, requiring less data preparation, and handling mixed data types. However, they are prone to overfitting, can be unstable to small data changes, and may become computationally expensive for very large datasets.\n",
        "\n",
        "Real-World Applications\n",
        "\n",
        "Medical Diagnosis: Diagnosing diseases by analyzing patient data, such as blood pressure and glucose levels.\n",
        "\n",
        "Banking & Finance: Assessing loan applications, detecting fraudulent transactions, and predicting credit risk.\n",
        "\n",
        "Marketing: Predicting customer churn, identifying customer segments, and analyzing marketing campaign effectiveness.\n",
        "\n",
        "Education: Predicting student performance (pass/fail) based on attendance, study time, and past grades to identify at-risk students.\n",
        "\n",
        "Business Strategic Planning: Mapping out long-term strategies and resource allocation by evaluating different criteria and outcomes.\n",
        "\n",
        "Advantages\n",
        "\n",
        "Interpretability: Decision trees are visual and easy to understand, making their logic clear even to non-technical users.\n",
        "\n",
        "Data Preparation: They require minimal data preprocessing, such as data cleaning or normalization, compared to other machine learning algorithms.\n",
        "\n",
        "Handles Mixed Data Types: Decision trees can work with both numerical and categorical data.\n",
        "\n",
        "Versatility: They can be used for both classification (predicting a category) and regression (predicting a continuous value) tasks.\n",
        "\n",
        "Feature Importance: They provide a clear way to assess the importance of different features in the decision-making process.\n",
        "\n",
        "Limitations\n",
        "\n",
        "Overfitting: Decision trees are prone to overfitting, especially with complex datasets, where the tree learns the training data too well and doesn't generalize to new data.\n",
        "\n",
        "Instability: Small changes in the training data can lead to significant changes in the tree's structure, making them unstable.\n",
        "\n",
        "Computational Cost: Building and training decision trees can be computationally expensive and complex, particularly for very large datasets.\n",
        "\n",
        "Bias: Decision trees can be biased toward features with more categories.\n",
        "\n",
        "Non-Continuous Nature: While they can handle continuous variables, the splits are always discrete, which can limit their performance on some problems."
      ],
      "metadata": {
        "id": "bruc4zLGooD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6: Write a Python program to:\n",
        "# Load the Iris Dataset\n",
        "# Train a Decision Tree Classifier using the Gini criterion\n",
        "# Print the modelâs accuracy and feature importances\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "# Answer:\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier using Gini criterion\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "# Feature importances\n",
        "print(\"Feature Importances:\")\n",
        "for feature_name, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feFuv3aIpdaF",
        "outputId": "5bdcdc49-0c2e-4619-ac1a-e3786a8d0f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n",
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Write a Python program to:\n",
        "# Load the Iris Dataset\n",
        "# Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree.\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "# Answer:\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Fully-grown decision tree\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# Decision tree with max_depth = 3\n",
        "clf_depth3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_depth3.fit(X_train, y_train)\n",
        "y_pred_depth3 = clf_depth3.predict(X_test)\n",
        "accuracy_depth3 = accuracy_score(y_test, y_pred_depth3)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy of Fully-grown Tree:\", accuracy_full)\n",
        "print(\"Accuracy of Tree with max_depth=3:\", accuracy_depth3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PReuYC7cp-nu",
        "outputId": "12bbab45-cce7-40b2-fbe1-f57d41cae529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Fully-grown Tree: 1.0\n",
            "Accuracy of Tree with max_depth=3: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: Write a Python program to:\n",
        "# Load the California Housing dataset from sklearn\n",
        "# Train a Decision Tree Regressor\n",
        "# Print the Mean Squared Error (MSE) and feature importances\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "# Answer:\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train a Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Feature Importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature_name, importance in zip(housing.feature_names, regressor.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ou6ZolNqgKi",
        "outputId": "ab6de61d-2b88-40ec-d844-6ada8d893ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.495235205629094\n",
            "\n",
            "Feature Importances:\n",
            "MedInc: 0.5285\n",
            "HouseAge: 0.0519\n",
            "AveRooms: 0.0530\n",
            "AveBedrms: 0.0287\n",
            "Population: 0.0305\n",
            "AveOccup: 0.1308\n",
            "Latitude: 0.0937\n",
            "Longitude: 0.0829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Write a Python program to:\n",
        "# Load the Iris Dataset\n",
        "# Tune the Decision Treeâs max_depth and min_samples_split using\n",
        "# GridSearchCV\n",
        "# Print the best parameters and the resulting model accuracy\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "# Answer:\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "# Initialize Decision Tree and GridSearchCV\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=dt,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,              # 5-fold cross-validation\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy with Best Parameters:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEzs-_q-qmeV",
        "outputId": "ecd56955-2de8-4dfe-922f-dc6b19999c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
            "Model Accuracy with Best Parameters: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecdfa8ac"
      },
      "source": [
        "### Question 10: Imagine youâre working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values. Explain the step-by-step process you would follow to:\n",
        "â Handle the missing values\n",
        "\n",
        "â Encode the categorical features\n",
        "\n",
        "â Train a Decision Tree model\n",
        "\n",
        "â Tune its hyperparameters\n",
        "\n",
        "â Evaluate its performance\n",
        "\n",
        "And describe what business value this model could provide in the real-world setting.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**1) Quick data audit (first things first)**\n",
        "\n",
        "*   Compute missingness summary (per column, per row %).\n",
        "*   Visualize missingness patterns (matrix/heatmap).\n",
        "*   Check whether missingness correlates with the target or key features (MCAR / MAR / MNAR).\n",
        "*   Identify high-cardinality categoricals, text fields, timestamps, group keys (hospital/clinic), and class imbalance.\n",
        "\n",
        "**2) Handling missing values**\n",
        "\n",
        "*   Principles: always fit imputers only on training data (use Pipeline/ColumnTransformer â no leakage).\n",
        "*   Numeric:\n",
        "    *   If simple and robust: median imputation.\n",
        "    *   If relationships exist: IterativeImputer (MICE) or KNNImputer (costly on very large data).\n",
        "    *   If missingness may be informative: add a binary indicator column feature_x_was_missing.\n",
        "    *   For grouped/clustered data: impute by group median (e.g., median by hospital, age bucket).\n",
        "*   Categorical:\n",
        "    *   Treat missing as its own category (\"MISSING\") or fill with mode if missing small & not informative.\n",
        "    *   For high-cardinality categories, consider frequency encoding (map to category frequency) rather than creating thousands of one-hot columns.\n",
        "*   Time / longitudinal:\n",
        "    *   Use forward/backward fill or model-based imputers that respect time ordering, if applicable.\n",
        "*   Practical rule: keep a log of all columns you drop and why (e.g., >70% missing and not clinically relevant).\n",
        "\n",
        "**3) Encoding categorical features (for tree models)**\n",
        "\n",
        "*   Low cardinality (â¤ ~10 unique): OneHotEncoder(handle_unknown='ignore') or OrdinalEncoder if truly ordinal.\n",
        "*   Moderate/high cardinality: frequency encoding or target/mean encoding.\n",
        "*   Important: if using target encoding, generate encodings out-of-fold (K-fold target encoding) to avoid leakage.\n",
        "*   Hashing or embedding approaches for extremely large cardinalities.\n",
        "*   Decision trees do not require scaling; integer encodings can work but avoid arbitrary numeric ordering unless ordinal.\n",
        "*   Implement encoders inside a ColumnTransformer so they are applied during cross-validation only on training folds.\n",
        "\n",
        "**4) Train the Decision Tree**\n",
        "\n",
        "*   Split data: stratified train / val / test (e.g., 60/20/20) or time-aware split for temporal data.\n",
        "*   Start with a baseline DecisionTree (class_weight='balanced' if class imbalance) to set expectations.\n",
        "*   Build a Pipeline: imputers â encoders â DecisionTreeClassifier(random_state=...).\n",
        "*   Use sample weights or class_weight when costs differ between classes.\n",
        "*   Notes: Trees overfit easily â youâll control complexity with hyperparameters.\n",
        "\n",
        "**5) Hyperparameter tuning**\n",
        "\n",
        "*   Key hyperparameters to search:\n",
        "    *   max_depth, min_samples_split, min_samples_leaf, max_leaf_nodes, max_features, criterion (gini/entropy), ccp_alpha (cost-complexity pruning), class_weight.\n",
        "*   Tuning strategy:\n",
        "    *   Use RandomizedSearchCV (or GridSearchCV for small grids) with StratifiedKFold.\n",
        "    *   Score/optimize for the clinically relevant metric (e.g., recall or average_precision/PR-AUC for rare disease).\n",
        "    *   Consider nested CV when you need an unbiased generalization estimate.\n",
        "    *   For large or expensive searches, use Bayesian optimization (Optuna) to find good regions faster.\n",
        "    *   Always check the best model on a held-out test set (never used during tuning).\n",
        "\n",
        "**6) Evaluate performance (metrics & procedures)**\n",
        "\n",
        "*   Choose metrics by clinical priorities:\n",
        "    *   If missing a case is costly: prioritize Recall / Sensitivity, monitor Precision and PR-AUC.\n",
        "    *   If false positives are costly: emphasize Precision and Specificity.\n",
        "*   Common metrics to report:\n",
        "    *   Confusion matrix, Accuracy, Precision, Recall, F1.\n",
        "    *   PR-AUC (average_precision) (preferable for imbalanced datasets) and ROC-AUC.\n",
        "    *   Calibration: calibration curve and Brier score (important if using probabilities for triage).\n",
        "    *   Decision threshold selection: choose threshold based on clinical cost matrix or operating point (e.g., maximize recall subject to minimum precision).\n",
        "*   Confidence intervals: bootstrap metrics to get uncertainty estimates.\n",
        "*   Subgroup analysis: evaluate across age, sex, ethnicity, hospital to detect bias and fairness issues.\n",
        "*   Consider decision curve analysis to quantify net clinical benefit.\n",
        "*   Reporting: include sample sizes, prevalence, and the operating threshold used.\n",
        "\n",
        "**7) Interpretability & explainability**\n",
        "\n",
        "*   Use global feature importances and SHAP for local explanations (why a particular patient was flagged).\n",
        "*   Extract and present a few human-readable rules (top branches) for clinicians.\n",
        "*   Visualize the tree (first few levels) and partial dependence plots for key features.\n",
        "*   Document limitations, expected failure modes, and features clinicians should not rely on blindly.\n",
        "\n",
        "**8) Deployment, monitoring & governance**\n",
        "\n",
        "*   Start with silent / shadow deployment (model runs but doesnât influence care) to collect real outcomes.\n",
        "*   Define actions for positive predictions (e.g., further testing, specialist review) â design a human-in-the-loop workflow.\n",
        "*   Monitor data drift (feature distribution changes) and performance drift; log inputs, predictions, and downstream labels.\n",
        "*   Retrain policy: triggers based on drift or time schedules.\n",
        "*   Ensure privacy/compliance (HIPAA / local regulations), versioning, and auditability.\n",
        "*   Get clinical validation (prospective study / pilot) before full automation.\n",
        "\n",
        "**9) Business value (real-world impact)**\n",
        "\n",
        "*   Early detection & triage: faster identification of high-risk patients, enabling earlier intervention and better outcomes.\n",
        "*   Resource allocation: focus scarce diagnostics and specialist time where theyâre most needed.\n",
        "*   Cost savings: fewer late-stage treatments and more efficient use of expensive tests.\n",
        "*   Operational KPIs: reduce time-to-diagnosis, reduce unnecessary admissions/tests, improve throughput.\n",
        "*   Patient experience & outcomes: quicker care pathways for those flagged, reduced complications.\n",
        "*   Research & insights: identify risk factor patterns and patient subgroups for clinical study.\n",
        "*   Caveat: Because false negatives in healthcare can be costly, design thresholds and workflows to minimize missed cases and validate clinically."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, average_precision_score\n",
        "from sklearn.datasets import load_iris # Import load_iris\n",
        "\n",
        "# Load the Iris dataset as an example\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Assume X and y are already loaded and represent your dataset and target variable\n",
        "# Split data into training and testing sets (stratified for class imbalance)\n",
        "# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "# preprocess\n",
        "# Replace with your actual column names\n",
        "num_cols = [0, 1, 2, 3]   # numeric column names for Iris dataset\n",
        "cat_cols = []   # low-cardinality categoricals for Iris dataset\n",
        "\n",
        "num_pipe = Pipeline([('impute', SimpleImputer(strategy='median'))])\n",
        "cat_pipe = Pipeline([('impute', SimpleImputer(strategy='constant', fill_value='MISSING')),\n",
        "                     ('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "pre = ColumnTransformer([('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)])\n",
        "\n",
        "# pipeline\n",
        "pipe = Pipeline([('pre', pre),\n",
        "                 ('clf', DecisionTreeClassifier(class_weight='balanced', random_state=0))])\n",
        "\n",
        "# hyperparam search\n",
        "param_dist = {\n",
        "  'clf__max_depth': [3,5,7,10,None],\n",
        "  'clf__min_samples_leaf': [1,2,5,10],\n",
        "  'clf__ccp_alpha': [0.0, 1e-4, 1e-3, 1e-2]\n",
        "}\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "search = RandomizedSearchCV(pipe, param_dist, n_iter=30, scoring='average_precision', cv=cv, random_state=0)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "# evaluate\n",
        "y_pred = search.predict(X_test)\n",
        "y_proba = search.predict_proba(X_test) # Get probabilities for all classes\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"PR-AUC (macro average):\", average_precision_score(y_test, y_proba, average='macro')) # Calculate macro average PR-AUC"
      ],
      "metadata": {
        "id": "hggni2i2vFFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b666b4c9-d255-4d85-e0dc-19d6c09699bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.90      0.90      0.90        10\n",
            "           2       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.93      0.93      0.93        30\n",
            "weighted avg       0.93      0.93      0.93        30\n",
            "\n",
            "PR-AUC (macro average): 0.9389141414141414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlxeNkcWhjSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}